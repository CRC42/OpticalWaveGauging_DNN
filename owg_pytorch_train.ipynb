{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6IDRkUomgeK"
      },
      "source": [
        "原始代码： https://colab.research.google.com/drive/1Uyz2Wsm0pUQWuZ0t6DnBUm4mnmqUERLh#scrollTo=ISwXERZACOsz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gAsJJKDflnrj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ-XO3ZvtF8K"
      },
      "source": [
        "## 数据集："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnxpMBPGmy-Q",
        "outputId": "4e78f4b3-4d56-4b47-f26e-2990f19c2c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config_train.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile config_train.json\n",
        "{\n",
        "  \"samplewise_std_normalization\" : true,\n",
        "  \"samplewise_center\"  : true,\n",
        "  \"input_image_format\" : \"jpg\",\n",
        "  \"input_csv_file\"     : \"snap-training-dataset.csv\",\n",
        "  \"category\"           : \"H\",\n",
        "  \"prc_lower_withheld\": 0,\n",
        "  \"prc_upper_withheld\": 0,\n",
        "\n",
        "  \"horizontal_flip\"    : false,\n",
        "  \"vertical_flip\"      : false,\n",
        "  \"rotation_range\"     : 10,\n",
        "  \"width_shift_range\"  : 0.1,\n",
        "  \"height_shift_range\" : 0.1,\n",
        "  \"shear_range\"        : 0.05,\n",
        "  \"zoom_range\"         : 0.2,\n",
        "  \"fill_mode\"          : \"reflect\",\n",
        "\n",
        "  \"img_size\"           : 128,\n",
        "  \"num_epochs\"         : 200,\n",
        "  \"test_size\"          : 0.4,\n",
        "  \"dropout_rate\"       : 0.5,\n",
        "  \"epsilon\"            : 0.0001,\n",
        "  \"min_lr\"             : 0.0001,\n",
        "  \"factor\"             : 0.8\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "unEI_10DntdD"
      },
      "outputs": [],
      "source": [
        "with open('config_train.json') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# config variables\n",
        "imsize    = int(config[\"img_size\"])\n",
        "num_epochs = int(config[\"num_epochs\"])\n",
        "test_size = float(config[\"test_size\"])\n",
        "height_shift_range = float(config[\"height_shift_range\"])\n",
        "width_shift_range = float(config[\"width_shift_range\"])\n",
        "rotation_range = float(config[\"rotation_range\"])\n",
        "samplewise_std_normalization = config[\"samplewise_std_normalization\"]\n",
        "horizontal_flip = config[\"horizontal_flip\"]\n",
        "vertical_flip = config[\"vertical_flip\"]\n",
        "samplewise_center = config[\"samplewise_center\"]\n",
        "shear_range = float(config[\"shear_range\"])\n",
        "zoom_range = float(config[\"zoom_range\"])\n",
        "dropout_rate = float(config[\"dropout_rate\"])\n",
        "epsilon = float(config[\"epsilon\"])\n",
        "min_lr = float(config[\"min_lr\"])\n",
        "factor = float(config[\"factor\"])\n",
        "input_image_format = config[\"input_image_format\"]\n",
        "input_csv_file = config[\"input_csv_file\"]\n",
        "category = config[\"category\"]\n",
        "fill_mode = config[\"fill_mode\"]\n",
        "prc_lower_withheld = config['prc_lower_withheld']\n",
        "prc_upper_withheld = config['prc_upper_withheld']\n",
        "IMG_SIZE = (imsize, imsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46jqmcgnn60K",
        "outputId": "0c9fe316-23a1-4170-ba4e-3fa9727f3224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-19 22:53:12--  https://github.com/dbuscombe-usgs/OpticalWaveGauging_DNN/raw/master/snap-training-dataset.csv\n",
            "Connecting to 127.0.0.1:7890... connected.\n",
            "Proxy request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/OpticalWaveGauging/OpticalWaveGauging_DNN/raw/master/snap-training-dataset.csv [following]\n",
            "--2024-02-19 22:53:13--  https://github.com/OpticalWaveGauging/OpticalWaveGauging_DNN/raw/master/snap-training-dataset.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "Proxy request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/OpticalWaveGauging/OpticalWaveGauging_DNN/master/snap-training-dataset.csv [following]\n",
            "--2024-02-19 22:53:14--  https://raw.githubusercontent.com/OpticalWaveGauging/OpticalWaveGauging_DNN/master/snap-training-dataset.csv\n",
            "Connecting to 127.0.0.1:7890... connected.\n",
            "Proxy request sent, awaiting response... 200 OK\n",
            "Length: 43795 (43K) [text/plain]\n",
            "Saving to: ‘snap-training-dataset.csv.1’\n",
            "\n",
            "snap-training-datas 100%[===================>]  42.77K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-02-19 22:53:14 (476 KB/s) - ‘snap-training-dataset.csv.1’ saved [43795/43795]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/dbuscombe-usgs/OpticalWaveGauging_DNN/raw/master/snap-training-dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Kbzl8KsvsQuA"
      },
      "outputs": [],
      "source": [
        "def get_and_tidy_df(base_dir, input_csv_file, image_dir, category):\n",
        "\t'''复制原数据集，使容量为原来的5倍'''\n",
        "\tdf = pd.read_csv(os.path.join(base_dir, input_csv_file))\n",
        "\tdf['path'] = df['id'].map(lambda x: os.path.join(base_dir,\n",
        "\t\t                                                image_dir,'{}'.format(x)))\n",
        "\n",
        "\tdf = df.rename(index=str, columns={\" H\": \"H\", \" T\": \"T\"})\n",
        "\n",
        "\tif category == 'H':\n",
        "\t\tmean = df['H'].mean()\n",
        "\t\tdiv = df['H'].std()\n",
        "\t\tdf['zscore'] = df['H'].map(lambda x: (x-mean)/div)\n",
        "\telif category == 'T':\n",
        "\t\tmean = df['T'].mean()\n",
        "\t\tdiv = df['T'].std()\n",
        "\t\tdf['zscore'] = df['T'].map(lambda x: (x-mean)/div)\n",
        "\telse:\n",
        "\t\tprint(\"Unknown category: \"+str(category))\n",
        "\t\tprint(\"Fix config file, exiting now ...\")\n",
        "\t\tsys.exit()\n",
        "\n",
        "\tdf.dropna(inplace = True)\n",
        "\ttry:\n",
        "\t\tdf = df.sort_values(by='time', axis=0)\n",
        "\texcept:\n",
        "\t\tdf = df.sort_values(by='id', axis=0)\n",
        "\n",
        "\tif category == 'H':\n",
        "\t\tdf['category'] = pd.cut(df['H'], 10)\n",
        "\telse:\n",
        "\t\tdf['category'] = pd.cut(df['T'], 8)\n",
        "\n",
        "\tdf['index1'] = df.index; new_df = df.groupby(['category']).apply(lambda x: x.sample(int(len(df)/2), replace = True)).reset_index(drop = True)\n",
        "\n",
        "\treturn new_df, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jruzi_pwtI0s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_145503/3895373730.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  df['index1'] = df.index; new_df = df.groupby(['category']).apply(lambda x: x.sample(int(len(df)/2), replace = True)).reset_index(drop = True)\n",
            "/tmp/ipykernel_145503/3895373730.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df['index1'] = df.index; new_df = df.groupby(['category']).apply(lambda x: x.sample(int(len(df)/2), replace = True)).reset_index(drop = True)\n"
          ]
        }
      ],
      "source": [
        "# call the utils.py function get_and_tidy_df\n",
        "image_dir = 'snap_images/data'\n",
        "new_df, df = get_and_tidy_df(os.getcwd(), input_csv_file, image_dir, category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bANGpCrZtmM1",
        "outputId": "c37b3d9a-f390-4a3a-cf13-da4df612275c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Data Size: 4900 Old Size: 980\n",
            "train 2940 validation 1960\n"
          ]
        }
      ],
      "source": [
        "print('New Data Size:', new_df.shape[0], 'Old Size:', df.shape[0])\n",
        "\n",
        "train_df, valid_df = train_test_split(new_df,\n",
        "                    test_size = test_size,\n",
        "                    random_state = 2018,\n",
        "                    stratify = new_df['category'])\n",
        "print('train', train_df.shape[0], 'validation', valid_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U67FHrDxi9m3"
      },
      "outputs": [],
      "source": [
        "if category==\"H\":\n",
        "  idx_label = 2\n",
        "elif category==\"T\":\n",
        "  idx_label = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yZDCG5JulvOE"
      },
      "outputs": [],
      "source": [
        "class WaveHeightDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx, 4]\n",
        "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "        label = self.dataframe.iloc[idx, idx_label]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mtzgJxxVlwLp"
      },
      "outputs": [],
      "source": [
        "# 数据转换与增强\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),  # 调整图像大小\n",
        "    # transforms.RandomHorizontalFlip(),  # 水平翻转\n",
        "    # transforms.RandomVerticalFlip(),  # 垂直翻转\n",
        "    transforms.RandomRotation(10),  # 随机旋转\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=shear_range, scale=(0.8, 1.2)),  # 位移、剪切和缩放\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # 归一化\n",
        "])\n",
        "\n",
        "# 数据加载\n",
        "train_dataset = WaveHeightDataset(train_df, transform=transform)\n",
        "test_dataset = WaveHeightDataset(valid_df, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGDGzLbJhke9",
        "outputId": "3916843b-3781-4eeb-8bfd-1d85067b3ec3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                                     1516464000.cx.snap.jpg\n",
              "time                                               1516464000\n",
              "H                                                        1.79\n",
              "T                                                       14.15\n",
              "path        /home/ubuntu/Documents/OpticalWaveGauging_DNN/...\n",
              "zscore                                                1.91159\n",
              "category                                       (1.692, 1.909]\n",
              "index1                                                    422\n",
              "Name: 3047, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KoDqBvdflx4L"
      },
      "outputs": [],
      "source": [
        "class OWGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OWGNet, self).__init__()\n",
        "        self.mobilenet = models.mobilenet_v2(pretrained=False)\n",
        "        self.mobilenet.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(1280, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mobilenet.features(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, 1)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KExl7Xpylz_1",
        "outputId": "ca24f80d-39f7-4fe5-e758-567c941cff77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/torch220/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/torch220/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device: \" + str(device))\n",
        "\n",
        "model = OWGNet().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 指定保存模型的路径\n",
        "checkpoint_path = 'checkPoints/model_checkpoint.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "xZvFfob1l1qt",
        "outputId": "0385943b-dd46-4b76-f8cb-1f5d5552c9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 0.39730702138141444\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Parent directory checkPoints does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 在每个epoch后保存模型checkpoint\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 你可以选择保存更多的信息，如优化器的状态\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/torch220/lib/python3.10/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    625\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/torch220/lib/python3.10/site-packages/torch/serialization.py:502\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/torch220/lib/python3.10/site-packages/torch/serialization.py:473\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory checkPoints does not exist."
          ]
        }
      ],
      "source": [
        "num_epochs = 100  # 根据需要调整\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}')\n",
        "    \n",
        "    # 在每个epoch后保存模型checkpoint\n",
        "    # 你可以选择保存更多的信息，如优化器的状态\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': train_loss,\n",
        "    }, checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载模型checkpoint\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "# 在恢复训练之前，确保模型处于训练模式\n",
        "model.train()\n",
        "# 接着可以继续训练或进行评估..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtf85-7ll3qx"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():  # 在评估阶段不计算梯度\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
        "            outputs = model(images)\n",
        "            predictions.extend(outputs.view(-1).cpu().numpy())  # 将预测保存起来\n",
        "            actuals.extend(labels.view(-1).cpu().numpy())  # 保存真实标签\n",
        "    return actuals, predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAxwPCnzl50L"
      },
      "outputs": [],
      "source": [
        "actuals, predictions = evaluate_model(model, test_loader, device)\n",
        "\n",
        "# 绘制实际值与预测值的对比图\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(actuals, predictions, alpha=0.5)\n",
        "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r')  # 绘制理想线\n",
        "plt.xlabel('Actual Wave Height (m)')\n",
        "plt.ylabel('Predicted Wave Height (m)')\n",
        "plt.title('Actual vs. Predicted Wave Heights')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY2LVyzFl7kH"
      },
      "outputs": [],
      "source": [
        "def show_predictions(test_loader, model, device, num_images=5):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(test_loader))\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(20, 4))\n",
        "    with torch.no_grad():\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        for i in range(num_images):\n",
        "            ax = axes[i]\n",
        "            img = images[i].cpu().squeeze()  # 移除批处理维度\n",
        "            label = labels[i].item()\n",
        "            prediction = outputs[i].item()\n",
        "            ax.imshow(img.numpy(), cmap='gray')\n",
        "            ax.set_title(f'True: {label:.3f}\\nPred: {prediction:.3f}')\n",
        "            ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 显示一些预测结果\n",
        "show_predictions(test_loader, model, device, num_images=5)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
